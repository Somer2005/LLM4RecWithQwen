{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21157d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['toy', 'story', 'adventure', 'animation', 'children', 'comedy', 'fantasy'], ['jumanji', 'adventure', 'children', 'fantasy'], ['grumpier', 'old', 'men', 'comedy', 'romance']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 读取 movies.csv\n",
    "df = pd.read_csv(\"/root/autodl-tmp/LLM4RecWithQwen/data/movies.csv\")\n",
    "\n",
    "def clean_text(title, genres):\n",
    "    # title: 去掉年份，全部小写\n",
    "    title = re.sub(r\"\\(\\d{4}\\)\", \"\", title).strip().lower()\n",
    "    \n",
    "    # genres: 用空格代替 |\n",
    "    genres = genres.replace(\"|\", \" \").lower()\n",
    "    \n",
    "    # 拼在一起\n",
    "    text = title + \" \" + genres\n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df.apply(lambda x: clean_text(x[\"title\"], x[\"genres\"]), axis=1)\n",
    "\n",
    "df.head()\n",
    "sentences = [row.split() for row in df[\"text\"].tolist()]\n",
    "print(sentences[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d3f741-6bfd-4d8c-a648-99f370a95e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec 训练完成！\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_dim = 128   # embedding维度\n",
    "w2v = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=w2v_dim,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=4,\n",
    "    sg=1  # 1=skip-gram，效果更好\n",
    ")\n",
    "\n",
    "print(\"Word2Vec 训练完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ab9304-f132-4e3e-9cce-d41cb9a03ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失词数量: 0\n",
      "电影 embedding 数量: 9742\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "movie_embeddings = {}\n",
    "missing_word = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    movie_id = row[\"movieId\"]\n",
    "    words = row[\"text\"].split()\n",
    "\n",
    "    vecs = []\n",
    "    for w in words:\n",
    "        if w in w2v.wv:\n",
    "            vecs.append(w2v.wv[w])\n",
    "        else:\n",
    "            missing_word += 1\n",
    "\n",
    "    # 平均 pooling\n",
    "    if len(vecs) > 0:\n",
    "        movie_embeddings[movie_id] = np.mean(vecs, axis=0)\n",
    "    else:\n",
    "        # 如果没有词，就用零向量\n",
    "        movie_embeddings[movie_id] = np.zeros(w2v_dim)\n",
    "\n",
    "print(\"缺失词数量:\", missing_word)\n",
    "print(\"电影 embedding 数量:\", len(movie_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8467861f-80cc-4adc-bfaa-504bc55f006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存 movie_embeddings.npy !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 转成矩阵格式：按 movieId 排序\n",
    "movie_ids = sorted(movie_embeddings.keys())\n",
    "matrix = np.array([movie_embeddings[mid] for mid in movie_ids])\n",
    "\n",
    "np.save(\"movie_embeddings.npy\", matrix)\n",
    "np.save(\"movie_ids.npy\", np.array(movie_ids))\n",
    "\n",
    "print(\"已保存 movie_embeddings.npy !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "441d5ee9-eeec-41c3-b64e-952730ec3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(\"/root/autodl-tmp/LLM4RecWithQwen/data/ratings.csv\")  # userId,movieId,rating,timestamp\n",
    "user_history = ratings.groupby(\"userId\")[\"movieId\"].apply(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483871f1-2eb7-4eb6-847b-3fa08a58e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "movie_emb = np.load(\"movie_embeddings.npy\")  # shape: (num_movies, emb_dim)\n",
    "movie_ids = np.load(\"movie_ids.npy\")\n",
    "movieId2index = {mid: i for i, mid in enumerate(movie_ids)}\n",
    "emb_dim = movie_emb.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e81cd7-0add-439a-afe3-90a32158ec8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_4067/3626740158.py:37: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  movie_vecs = torch.tensor([movie_emb[movieId2index[m]] for m in valid_movies],\n",
      "610it [00:12, 48.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户 embedding 已生成并保存！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 自动获取 embedding 维度\n",
    "# -----------------------------\n",
    "emb_dim = movie_emb.shape[1]  # movie_emb 已经加载了 movie_embeddings.npy\n",
    "\n",
    "# -----------------------------\n",
    "# 用户塔模型\n",
    "# -----------------------------\n",
    "class UserTower(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(emb_dim, emb_dim)\n",
    "        )\n",
    "    def forward(self, movie_emb_list):\n",
    "        return self.mlp(movie_emb_list.mean(dim=0))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "user_tower = UserTower(emb_dim).to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 生成用户 embedding\n",
    "# -----------------------------\n",
    "user_embeddings_dict = {}\n",
    "for uid, movies in tqdm(user_history.items()):\n",
    "    valid_movies = [m for m in movies if m in movieId2index]\n",
    "    if not valid_movies:\n",
    "        user_embeddings_dict[uid] = np.zeros(emb_dim, dtype=np.float32)\n",
    "        continue\n",
    "    movie_vecs = torch.tensor([movie_emb[movieId2index[m]] for m in valid_movies],\n",
    "                              dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        user_vec = user_tower(movie_vecs).cpu().numpy()\n",
    "    user_embeddings_dict[uid] = user_vec\n",
    "\n",
    "# -----------------------------\n",
    "# 保存成 numpy 矩阵 + userIds\n",
    "# -----------------------------\n",
    "user_ids = sorted(user_embeddings_dict.keys())\n",
    "matrix = np.array([user_embeddings_dict[uid] for uid in user_ids])\n",
    "np.save(\"user_embeddings.npy\", matrix)\n",
    "np.save(\"user_ids.npy\", np.array(user_ids))\n",
    "\n",
    "print(\"用户 embedding 已生成并保存！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e67204-d869-4abb-82e4-0fc4f7c39d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
